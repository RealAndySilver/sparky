{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc3d3bc-8b23-4cf5-abcd-0775db8151f5",
   "metadata": {},
   "source": [
    "## Add dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e991a2-e3f1-44ad-b06e-0ab203cef7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import math\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafea26f-df69-47a8-b966-df69cff1f97f",
   "metadata": {},
   "source": [
    "### Spark session & context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78330b-8060-4f1f-90a3-157fae696bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2f471-0180-4079-aa99-5a963128ba9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925bf2a8-e2ff-4ede-938e-b5f32d94a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = spark.read.csv('data/underdrain.csv',\n",
    "                         header=True,\n",
    "                         inferSchema=True)\n",
    "data_df.printSchema()\n",
    "filtered_df = data_df.filter(data_df.DCH_INSTALL_DATE.isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ddae0e-6e37-4929-b767-e902842ebe10",
   "metadata": {},
   "source": [
    "### Logic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f787a-958b-409d-b9f9-3e5498b1f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp(date_text):\n",
    "    \"\"\"Get timestamp from date text\"\"\"\n",
    "    try:\n",
    "        date_text = datetime.strptime(date_text, '%Y/%m/%d %H:%M:%S+00')\n",
    "    except ValueError:\n",
    "        date_text = datetime.strptime(\n",
    "            \"1900/01/01 01:01:01+00\", '%Y/%m/%d %H:%M:%S+00')\n",
    "\n",
    "    return date_text.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42285c-d215-4b9d-831e-ad3bd4583531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_time_to_resolution(timestamp, resolution=1):\n",
    "    \"\"\"Snap time to resolution\"\"\"\n",
    "    if resolution <= 0:\n",
    "        resolution = 1\n",
    "    resolution_ms = resolution * 60\n",
    "    snapped_time = datetime.fromtimestamp(\n",
    "        math.floor(timestamp / resolution_ms) * resolution_ms)\n",
    "\n",
    "    return snapped_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a03913-0204-4655-b406-9be9c41b084b",
   "metadata": {},
   "source": [
    "# Create UDF\n",
    "\n",
    "*There are 2 ways of registering a UDF*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61484e4a-10a4-43e0-9843-57c6c75c18a2",
   "metadata": {},
   "source": [
    "### Way #1: \n",
    "\n",
    "*add annotation **@udf()** on top of the function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453af9c-7576-431a-9940-6bf8ce03c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=TimestampType())\n",
    "def snap_row(date, resolution=15):\n",
    "    \"\"\"Snap row to resolution\"\"\"\n",
    "    timestamp = get_timestamp(date)\n",
    "    snapped_time = snap_time_to_resolution(timestamp, resolution)\n",
    "    return snapped_time\n",
    "\n",
    "filtered_df.withColumn('SNAPPED_TIME', snap_row(filtered_df.DCH_INSTALL_DATE)).write.mode(\"overwrite\").csv(\"data/csvs\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f6fdb0-7853-44b6-9cfa-aa161e9bb3e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Way #2: \n",
    "\n",
    "\n",
    "*use the **udf()** function and wrap the function to register and a type as 2nd arg*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8d071-5fe7-405d-96e5-170b7fda6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def snap_row(date, resolution=15):\n",
    "#     \"\"\"Snap row to resolution\"\"\"\n",
    "#     timestamp = get_timestamp(date)\n",
    "#     snapped_time = snap_time_to_resolution(timestamp, resolution)\n",
    "#     return snapped_time\n",
    "\n",
    "# snap_udf = udf(snap_row, 'timestamp')\n",
    "# filtered_df.withColumn('SNAPPED_TIME', snap_udf(filtered_df.DCH_INSTALL_DATE)).write.mode(\"overwrite\").csv(\"data/csvs\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd8331-7b3f-405e-b579-b518e5c52268",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW USER FUNCTIONS\").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
